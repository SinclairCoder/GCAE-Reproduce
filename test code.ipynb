{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree\n",
    "from collections import defaultdict, Counter\n",
    "import argparse\n",
    "import datetime\n",
    "import torch\n",
    "import torchtext.data as data\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from torchtext.vocab import Vectors\n",
    "from torch.nn import init\n",
    "from torchtext.vocab import GloVe\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_atsa_laptop = {'train': 'data/atsa-laptop/atsa_train.json','test': 'data/atsa-laptop/atsa_test.json','hard_test':'data/atsa-laptop/atsa_hard_test.json'}\n",
    "ds_atsa_restaurant = {'train': 'data/atsa-restaurant/atsa_train.json','test': 'data/atsa-restaurant/atsa_test.json','hard_test':'data/atsa-restaurant/atsa_hard_test.json'}\n",
    "ds_atsa = {'laptop':ds_atsa_laptop,'rest':ds_atsa_restaurant}\n",
    "\n",
    "ds_acsa_large = {'train': 'data/acsa-restaurant-large/acsa_train.json','test':'data/acsa-restaurant-large/acsa_test.json','hard_test':'data/acsa-restaurant-large/acsa_hard_test.json'}\n",
    "ds_acsa_2014 = {'train': 'data/acsa-restaurant-2014/acsa_train.json','test':'data/acsa-restaurant-2014/acsa_test.json','hard_test':'data/acsa-restaurant-2014/acsa_hard_test.json'}\n",
    "ds_acsa = {'large':ds_acsa_large,'2014':ds_acsa_2014}\n",
    "ds_files ={'atsa':ds_atsa,'acsa':ds_acsa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip()\n",
    "\n",
    "def get_data_from_json(file_path):\n",
    "        with open(file_path,'r') as load_f:\n",
    "            dataset = json.load(load_f)\n",
    "            return dataset\n",
    "def load_semeval_data(text_field,aspect_field,sentiment_field,dataset_file):\n",
    "    semeval_train = get_data_from_json(dataset_file['train'])\n",
    "    semeval_test = get_data_from_json(dataset_file['test'])\n",
    "    semeval_hard_test = get_data_from_json(dataset_file['hard_test'])\n",
    "    \n",
    "    train_data = SemEval(text_field,aspect_field,sentiment_field,semeval_train)\n",
    "    test_data = SemEval(text_field,aspect_field,sentiment_field,semeval_test)\n",
    "    hard_test_data = SemEval(text_field,aspect_field,sentiment_field,semeval_hard_test)\n",
    "    return train_data,test_data,hard_test_data\n",
    "\n",
    "class SemEval(data.Dataset):\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "    \n",
    "    def __init__(self,text_field,aspect_field,sentiment_field,input_data,**kwargs):\n",
    "        \"\"\" Create an SemEval Dataset instance given a path and fields.\n",
    "        \n",
    "        Arguments:\n",
    "            text_field: The field that will be used for text data.\n",
    "            aspect_field:  The field that will be used for aspect data.\n",
    "            sentiment_field: The field that will be used for sentiment data.\n",
    "            input_data: The examples contain all the data.\n",
    "            Remaining keyword arguments: Passed to the constructor of data.Dataset.\n",
    "        \n",
    "        \"\"\"\n",
    "        text_field.preprocessing = data.Pipeline(clean_str)\n",
    "        fields = [('text',text_field),('aspect',aspect_field),('sentiment',sentiment_field)]\n",
    "        examples = []\n",
    "        for e in input_data:\n",
    "            if 'pp.' in e['sentence']:\n",
    "                continue\n",
    "            examples.append(data.Example.fromlist([e['sentence'],e['aspect'],e['sentiment']],fields))\n",
    "        super(SemEval,self).__init__(examples,fields,**kwargs)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_field = data.Field(lower=True,tokenize='moses')\n",
    "aspect_field = data.Field(sequential=False)\n",
    "sentiment_field = data.Field(sequential=False)\n",
    "train_data, test_data,hard_test_data = load_semeval_data(text_field,aspect_field,sentiment_field,ds_files['acsa']['2014'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "text_field.build_vocab(train_data,test_data)\n",
    "aspect_field.build_vocab(train_data,test_data)\n",
    "sentiment_field.build_vocab(train_data,test_data)\n",
    "print(len(text_field.vocab))\n",
    "print(len(aspect_field.vocab))\n",
    "print(len(sentiment_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'positive', 'negative', 'neutral', 'conflict']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'food', 'misc', 'service', 'ambience', 'price']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x00000219D3970088>>,\n",
       "            {'<unk>': 0,\n",
       "             'food': 1,\n",
       "             'misc': 2,\n",
       "             'service': 3,\n",
       "             'ambience': 4,\n",
       "             'price': 5})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text_field.vocab.itos\n",
    "aspect_field.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(word_list,uniform_scale,dimension_size):\n",
    "    glove_words = {}\n",
    "    file_path = 'data/glove.6B.50d_test.txt'\n",
    "    with open(file_path,'r',encoding='UTF-8') as fopen:\n",
    "        for line in fopen:\n",
    "            tokens = line.rstrip().split()\n",
    "            glove_words[tokens[0]] = np.array(tokens[1:],dtype='float32')\n",
    "    word_vectors = []\n",
    "    for word in word_list:\n",
    "        if word in glove_words:\n",
    "            word_vectors.append(glove_words[word])\n",
    "        elif word == '<pad>':\n",
    "            word_vectors.append(np.zeros(dimension_size,dtype=np.float32))\n",
    "        else:\n",
    "            word_vectors.append(np.random.uniform(-uniform_scale,uniform_scale,dimension_size))\n",
    "#     word_vectors = np.asarray(word_vectors,dtype=np.float32)\n",
    "    return word_vectors\n",
    "word_vectors = load_glove(text_field.vocab.itos,0.25,300)\n",
    "def load_aspect_embedding_from_w2v(aspect_list,word_stoi,w2v):\n",
    "    aspect_vectors = []\n",
    "#     print(word_stoi)\n",
    "    for w in aspect_list:\n",
    "        print(w)\n",
    "        print(word_stoi[w])\n",
    "        aspect_vectors.append(w2v[word_stoi[w]])\n",
    "    return aspect_vectors\n",
    "load_aspect_embedding_from_w2v(aspect_field.vocab.itos,text_field.vocab.stoi,word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_word_vec(path, word2idx=None):\n",
    "    fin = open(path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    word_vec = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split() # rstrip()，删除string末尾的指定字符（默认为空格）\n",
    "        # 如果预训练词向量的包含的单词在语料中出现，就把单词及对应向量添加到字典中\n",
    "        if word2idx is None or tokens[0] in word2idx.keys():\n",
    "            word_vec[tokens[0]] = np.asarray(tokens[1:], dtype='float32')\n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_iter,test_iter, hard_test_iter = data.Iterator.splits((train_data,test_data,hard_test_data),batch_sizes=(batch_size,len(test_data),len(hard_test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SemEval at 0x219d3b50d48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 32])\n",
      "torch.Size([32])\n",
      "torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(1, epochs+1):\n",
    "        for batch in train_iter:\n",
    "            feature, aspect, target = batch.text, batch.aspect, batch.sentiment\n",
    "#             print(feature.t_())\n",
    "#             print(batch.text)\n",
    "            print(feature.shape)\n",
    "            print(aspect.shape)\n",
    "            aspect.unsqueeze_(0)\n",
    "            print(aspect.shape)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch text:  tensor([[   5,   12, 2072,  ...,    9,    3,  584],\n",
      "        [  82,  220,    7,  ...,   74,  414,   18],\n",
      "        [ 217,    4,    6,  ...,   37,  394,    4],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "batch aspect:  tensor([1, 1, 3, 1, 1, 3, 1, 5, 1, 2, 1, 2, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 2, 4,\n",
      "        2, 2, 5, 1, 2, 2, 1, 3])\n",
      "batch sentiment:  tensor([1, 1, 1, 1, 1, 3, 2, 2, 4, 1, 1, 1, 2, 1, 3, 1, 4, 1, 1, 1, 1, 1, 1, 2,\n",
      "        2, 1, 1, 1, 1, 1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(\"batch text: \", batch.text) # 对应 Fileld 的 name\n",
    "print(\"batch aspect: \", batch.aspect)\n",
    "print(\"batch sentiment: \", batch.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT = data.Field(sequential=True)\n",
    "# vectors = Vectors(name='data/glove.6B.50d_test.txt')\n",
    "# TEXT.build_vocab(train_data,test_data, vectors=vectors)\n",
    "# vectors.unk_init = init.xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32]\n",
       "\t[.text]:[torch.LongTensor of size 38x32]\n",
       "\t[.aspect]:[torch.LongTensor of size 32]\n",
       "\t[.sentiment]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACSA\n",
    "V = len(text_field.vocab) # 词表长度\n",
    "D = 300\n",
    "A = len(aspect_field.vocab)\n",
    "Co = 128 # kernel num\n",
    "Ks = [2,3,4]\n",
    "embed = nn.Embedding(V,D)\n",
    "aspect_embed = nn.Embedding(A,D)\n",
    "convs1 = nn.ModuleList([nn.Conv1d(D,Co,K) for K in Ks])\n",
    "convs2 = nn.ModuleList([nn.Conv1d(D,Co,K) for K in Ks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv1d(300, 128, kernel_size=(2,), stride=(1,))\n",
       "  (1): Conv1d(300, 128, kernel_size=(3,), stride=(1,))\n",
       "  (2): Conv1d(300, 128, kernel_size=(4,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ModuleList([nn.Conv1d(D,Co,K) for K in Ks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature,aspect = batch.text,batch.aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(5095, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 38])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 38, 300])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.t_()\n",
    "print(feature.shape)\n",
    "feature_embed = embed(feature)\n",
    "feature_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "print(aspect.shape)\n",
    "aspect.unsqueeze_(0)\n",
    "print(aspect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 300])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect.t_()\n",
    "print(aspect.shape)\n",
    "aspect_v = aspect_embed(aspect)\n",
    "aspect_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 300])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_v.sum(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_v.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 300])\n"
     ]
    }
   ],
   "source": [
    "aspect_v = aspect_v.sum(dim=1)/aspect_v.size(dim=1)\n",
    "print(aspect_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 38, 300])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.tanh(conv(feature_embed.transpose(1,2))) for conv in convs1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 37])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 36])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 35])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 44, 300])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=128, bias=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_aspect = nn.Linear(D,Co)\n",
    "fc_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_aspect(aspect_v).unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 38, 300])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [torch.relu(conv(feature_embed.transpose(1,2))+fc_aspect(aspect_v).unsqueeze(2)) for conv in convs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 37])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 36])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 35])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [i*j for i,j in zip(x,y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _VariableFunctions.max_pool1d>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max_pool1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 37])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max_pool1d(z[0],z[0].size(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = [torch.max_pool1d(i, i.size(2)).squeeze(2) for i in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = [i.view(i.size(0),-1) for i in z1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = torch.cat(z1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 384])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = nn.Linear(len(Ks)*Co, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=384, out_features=4, bias=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for k in [3]:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATSA\n",
    "text_field = data.Field(lower=True,tokenize='moses')\n",
    "aspect_field = data.Field(lower=True, tokenize='moses')\n",
    "sentiment_field = data.Field(sequential=False)\n",
    "train_data, test_data,hard_test_data = load_semeval_data(text_field,aspect_field,sentiment_field,ds_files['atsa']['laptop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3563\n",
      "988\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "text_field.build_vocab(train_data,test_data)\n",
    "aspect_field.build_vocab(train_data,test_data)\n",
    "sentiment_field.build_vocab(train_data,test_data)\n",
    "print(len(text_field.vocab))\n",
    "print(len(aspect_field.vocab))\n",
    "print(len(sentiment_field.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'positive', 'negative', 'neutral', 'conflict']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_iter,test_iter, hard_test_iter = data.Iterator.splits((train_data,test_data,hard_test_data),batch_sizes=(batch_size,len(test_data),len(hard_test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch text:  tensor([[   8,  115,   15,  ...,   66,   15,    2],\n",
      "        [  10,   88,   35,  ..., 1006,  295,  387],\n",
      "        [  55, 1670,  118,  ...,   16,   82,   10],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "batch aspect:  tensor([[  6, 124,   2, 209,   2,  53,  16,  79,  18,  32,   5, 470,  55, 440,\n",
      "           2,  24, 248, 779,   9,  61,  56, 201,   4,  85,  15, 253, 442,   3,\n",
      "          19, 138,  71, 345],\n",
      "        [  1, 319,   1,  27,   8,   1,  88,   1,   1,   1,   1,   1,  25,  10,\n",
      "           8,   1,   1, 297,   1,   1, 572,   1, 172,   1,  42,  34,   1,   1,\n",
      "           1, 371,  11,   1],\n",
      "        [  1,   1,   1, 188,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1, 624,   1,   1,   1,   1,   1,   1,   1,  25,   1,   1,\n",
      "           1,   1,   1,   1],\n",
      "        [  1,   1,   1,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1, 662,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1]])\n",
      "batch sentiment:  tensor([3, 2, 2, 1, 2, 2, 2, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 2, 3, 2,\n",
      "        1, 3, 1, 1, 3, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(\"batch text: \", batch.text) # 对应 Fileld 的 name\n",
    "print(\"batch aspect: \", batch.aspect)\n",
    "print(\"batch sentiment: \", batch.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect = batch.aspect\n",
    "aspect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  6, 124,   2, 209,   2,  53,  16,  79,  18,  32,   5, 470,  55, 440,\n",
       "           2,  24, 248, 779,   9,  61,  56, 201,   4,  85,  15, 253, 442,   3,\n",
       "          19, 138,  71, 345],\n",
       "        [  1, 319,   1,  27,   8,   1,  88,   1,   1,   1,   1,   1,  25,  10,\n",
       "           8,   1,   1, 297,   1,   1, 572,   1, 172,   1,  42,  34,   1,   1,\n",
       "           1, 371,  11,   1],\n",
       "        [  1,   1,   1, 188,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1, 624,   1,   1,   1,   1,   1,   1,   1,  25,   1,   1,\n",
       "           1,   1,   1,   1],\n",
       "        [  1,   1,   1,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1, 662,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = len(aspect_field.vocab) \n",
    "aspect_embed = nn.Embedding(A,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv1d(300, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convs3 = nn.ModuleList([nn.Conv1d(D, Co, K, padding=K-2) for K in [3]])\n",
    "convs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=128, bias=True)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_aspect1 = nn.Linear(100, Co)\n",
    "fc_aspect1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 300])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_v1 = aspect_embed(aspect.t_())\n",
    "aspect_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [torch.relu(conv(aspect_v1.transpose(1,2))) for conv in convs3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 4])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max_pool1d(aa[0],aa[0].size(2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [torch.max_pool1d(a,a.size(2)).squeeze(2) for a in aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_v1 = torch.cat(aa,1)\n",
    "aspect_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 128], m2: [100 x 128] at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-579cf22e3f86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfc_aspect1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maspect_v1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Python\\Anaconda\\INSTALL\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\Anaconda\\INSTALL\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\Anaconda\\INSTALL\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 128], m2: [100 x 128] at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "fc_aspect1(aspect_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
